{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting getuseragent\n",
      "  Downloading getuseragent-0.0.7-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: getuseragent\n",
      "Successfully installed getuseragent-0.0.7\n"
     ]
    }
   ],
   "source": [
    "# ! pip install getuseragent\n",
    "# ! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium\n",
    "from selenium import webdriver\n",
    "#from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# BeautifulSoup e Request\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from getuseragent import UserAgent\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "useragent = UserAgent()\n",
    "\n",
    "theuseragent = useragent.Random()\n",
    "headers = {'User-Agent': theuseragent}\n",
    "header = {\n",
    "    \"user-agent\": theuseragent ,\n",
    "    'referer':'https://www.google.com/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allow_cookies(driver):    \n",
    "    button_setting_cookies = driver.find_element(By.CSS_SELECTOR, \"button.cookie-setting-link\")\n",
    "    button_setting_cookies.click()\n",
    "    time.sleep(np.random.choice([x/10 for x in range(7,22)]))    \n",
    "    button_confirm_cookies = driver.find_element(By.CSS_SELECTOR, \"button.save-preference-btn-handler\")\n",
    "    #Conferma le mie scelte\n",
    "    button_confirm_cookies.click()\n",
    "\n",
    "def next_page():\n",
    "    next_button = driver.find_element(By.CSS_SELECTOR, \"button.nextButton\")\n",
    "    next_button.click()\n",
    "    url = driver.current_url\n",
    "\n",
    "def parse_url(url):\n",
    "    company_name = []\n",
    "    job_title=[]\n",
    "    location=[]\n",
    "    company_rating=[]\n",
    "    job_age=[]\n",
    "    job_link=[]\n",
    "    \n",
    "    r = requests.get(url, headers=header)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    job_search_div = soup.select('div#JobSearch')[0]\n",
    "    a = job_search_div.select('div#PageBodyContents')\n",
    "    b = a[0].select('div#JobResults')\n",
    "    c = b[0].select('article#MainCol')\n",
    "    len_li = len(c[0].find_all('li', class_='react-job-listing'))\n",
    "    lis = c[0].find_all('li', class_='react-job-listing')\n",
    "    \n",
    "    len_li = len(lis)\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    for e in lis[0:len_li]:\n",
    "        try:\n",
    "            company_name.append(e.find('div').find('a')['title'])\n",
    "        except:\n",
    "            company_name.append(None)\n",
    "        try:\n",
    "            job_title.append(e['data-normalize-job-title'])\n",
    "        except:\n",
    "            job_title.append(None)    \n",
    "        try:\n",
    "            location.append(e['data-job-loc'])\n",
    "        except:\n",
    "            location.append(None)\n",
    "        try:\n",
    "            company_rating.append(e.find('span', class_='css-2lqh28')) ### da controllare\n",
    "        except:\n",
    "            company_rating.append(None)\n",
    "        try:\n",
    "            job_age.append(e.find(\"div\", {\"data-test\": \"job-age\"}).text)\n",
    "        except:\n",
    "            job_link.append(None)\n",
    "        try:\n",
    "            link = \"https://www.glassdoor.it\" + e.find(\"a\", {\"data-test\": \"job-link\"}).get(\"href\")\n",
    "            job_link.append(link)\n",
    "        except:\n",
    "            job_link.append(None)\n",
    "            \n",
    "    df['company'] = company_name\n",
    "    df['job_title'] = job_title\n",
    "    df['location'] = location\n",
    "    df['company_rating']=company_rating\n",
    "    df['job_age'] = job_age\n",
    "    df['job_link']=job_link\n",
    "    \n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/notebook'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_executor='http://192.168.99.101:4444/wd/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_398/281602694.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"\\home\\jovyan\\notebook\\web_chromedriver\\chromedriver.exe\")\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: Service \\home\\jovyan\\notebook\\web_chromedriver\\chromedriver.exe unexpectedly exited. Status code was: 127\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df_append \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# driver = webdriver.Chrome(r\"C:\\Users\\Casulippo\\Desktop\\web_chromedriver\\chromedriver.exe\")\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mhome\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mjovyan\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mnotebook\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mweb_chromedriver\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mchromedriver.exe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.glassdoor.it/Lavoro/milano-lavori-SRCH_IL.0,6_IC2802090.htm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(base_url)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/selenium/webdriver/chrome/webdriver.py:80\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m service:\n\u001b[1;32m     78\u001b[0m     service \u001b[38;5;241m=\u001b[39m Service(executable_path, port, service_args, service_log_path)\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesired_capabilities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/selenium/webdriver/chromium/webdriver.py:101\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m service\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    105\u001b[0m         command_executor\u001b[38;5;241m=\u001b[39mChromiumRemoteConnection(\n\u001b[1;32m    106\u001b[0m             remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    113\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/selenium/webdriver/common/service.py:104\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_process_still_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connectable():\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/selenium/webdriver/common/service.py:117\u001b[0m, in \u001b[0;36mService.assert_process_still_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m return_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mService \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m unexpectedly exited. Status code was: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: Service \\home\\jovyan\\notebook\\web_chromedriver\\chromedriver.exe unexpectedly exited. Status code was: 127\n"
     ]
    }
   ],
   "source": [
    "df_append = pd.DataFrame()\n",
    "# driver = webdriver.Chrome(r\"C:\\Users\\Casulippo\\Desktop\\web_chromedriver\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(r\"\\home\\jovyan\\notebook\\web_chromedriver\\chromedriver.exe\")\n",
    "base_url = 'https://www.glassdoor.it/Lavoro/milano-lavori-SRCH_IL.0,6_IC2802090.htm'\n",
    "driver.get(base_url)\n",
    "a = np.random.choice([x for x in range(7,15)])\n",
    "time.sleep(a)\n",
    "url = driver.current_url\n",
    "allow_cookies(driver)\n",
    "a = np.random.choice([x for x in range(7,15)])\n",
    "time.sleep(a)\n",
    "r = requests.get(url, headers=header)\n",
    "\n",
    "text = BeautifulSoup(r.text, 'html.parser').find('div', attrs={'class': 'paginationFooter'}).text\n",
    "\n",
    "int_list=[]\n",
    "for e in re.findall(r'-?\\d+\\.?\\d*', text):\n",
    "    int_list.append(int(e))\n",
    "\n",
    "n_page = max(int_list)\n",
    "#n_page = 5\n",
    "print('Numero di pagine sui cui fare scraping: ' + str(n_page))\n",
    "a = np.random.choice([x for x in range(7,15)])\n",
    "time.sleep(a)\n",
    "\n",
    "for page in range(n_page):\n",
    "    print(str(page +1) + '/' + str(n_page))\n",
    "    a = np.random.choice([x for x in range(7,15)])\n",
    "    time.sleep(a)\n",
    "    next_page()\n",
    "    url = driver.current_url\n",
    "    if page == 0:\n",
    "        time.sleep(5)\n",
    "        close_button = driver.find_element(By.CSS_SELECTOR, \"svg.SVGInline-svg.modal_closeIcon-svg\")\n",
    "        close_button.click()\n",
    "    df = parse_url(url)\n",
    "    df_append = df_append.append(df).reset_index(drop=True)\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "    \n",
    "        \n",
    "df_append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Driver\n",
    "start_time = time.time()\n",
    "df_append_2 =pd.DataFrame()\n",
    "time_sleep = 0\n",
    "n_link = 0\n",
    "## lista dei link\n",
    "links=list(df_append['job_link'].unique())\n",
    "#base_url = 'https://www.glassdoor.it/job-listing/field-service-engineer-technician-lexas-JV_IC2802269_KO0,33_KE34,39.htm?jl=1008135983566&pos=101&ao=1110586&s=58&guid=000001861873f6d389d965e51ce717e2&src=GD_JOB_AD&t=SR&vt=w&uido=FEB79CBEB143B609D33C645CD13E2F4B&ea=1&cs=1_524e761d&cb=1675447498725&jobListingId=1008135983566&cpc=65CC663E25211861&jrtk=3-0-1goc77to1g2ev801-1goc77tp0i6id800-7cbed71e05432cdf--6NYlbfkN0CVO0F7mWis5ReNIXvK0Cy97GKSpj_H8mHyNoiV7tLwhxrGQFeFbXfrFFwDAnfvPXeiJe5SavTtAEQpKcpYVReYHZsV-4ZX7UeAkoBb0f_WCVWviQdPDhB0WcxVHddsJTu6CPWu9hRPncXvGLdy3ZffF5b3aOd7vp19QcNQdw0qQd1bkijbQHvL2CZX_Cxp4BGS1Sk8JgAjiz75HrAHRuR5hA9kjnxafzWfGAAOJBSKybBbJtFcKCvWC2Py0-IgF36KHcIY5QbFzm8TqI0WJJ75VyN8D93fcG7Ikeu9ECT-vBbPKtsVv7AOpI6elTa0KTJqDzeYeI39a8bHa5BUUOjrQ1rsJFwMGLJrLrbqXOIObHs1pSu_fpr-FcNbNcmvwdLQufgm_hOEka1AR5pS2jw3Kd3MEOLDniaBdQ1tk-tgoNuL5lhZNjQUe648ZgRuUWrLaIX3oHWCh15jyNqf9dfjjRB70aXgFCI2nC397dI72pLnPhLIqqOKxPTEV4El04FFBbjsdOPDp3q0LQurvyiZmQB21o9E3WEoCcol53Fx2g0SIc5ixunqT-a4RIeTz8CzvY7DdPxvqKSbekvmaTBa_UWB3gbtD9Y%253D&ctt=1675447519123'\n",
    "print('link to scrape: ', len(links))    \n",
    "\n",
    "for base_url in links: \n",
    "    n_link += 1\n",
    "    if (n_link = 30) | (n_link = 30) | (n_link = 30):\n",
    "        time_sleep(60)\n",
    "        \n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\Casulippo\\Desktop\\web_chromedriver\\chromedriver.exe\")\n",
    "    driver.get(base_url)\n",
    "    a = np.random.choice([x for x in range(7,15)])\n",
    "    time_sleep = time_sleep + a \n",
    "    time.sleep(a)\n",
    "    ## cookies\n",
    "    allow_cookies(driver)\n",
    "    a = np.random.choice([x for x in range(7,15)])\n",
    "    time_sleep = time_sleep + a \n",
    "    time.sleep(a)\n",
    "    ## Mapping dei bottoni\n",
    "    general_button = driver.find_elements(By.CSS_SELECTOR, \".css-dkrzi8.e1eh6fgm0\")\n",
    "    button_mapping = {valore.text: indice for indice, valore in enumerate(general_button)}\n",
    "\n",
    "    \n",
    "    d_valutazione={}\n",
    "    d_azienda={}\n",
    "\n",
    "    print('check the buttons-->', n_link)\n",
    "    try:\n",
    "        general_button = driver.find_elements(By.CSS_SELECTOR, \".css-dkrzi8.e1eh6fgm0\")\n",
    "        \n",
    "    except:\n",
    "        print('no buttons found')\n",
    "        general_button = []\n",
    "    \n",
    "    \n",
    "    if len(general_button)>0:\n",
    "        \n",
    "        try:\n",
    "\n",
    "            azienda = general_button[button_mapping['Azienda']] # Azienda\n",
    "            azienda.click()\n",
    "            pag_azienda_span = driver.find_elements(By.CSS_SELECTOR, \".css-vugejy.es5l5kg0 span.value\")\n",
    "            pag_azienda_value = driver.find_elements(By.CSS_SELECTOR, \".css-vugejy.es5l5kg0 label\")\n",
    "            \n",
    "            azienda_span = []\n",
    "            azienda_value = []\n",
    "            \n",
    "            for e in pag_azienda_span:\n",
    "                azienda_span.append(e.text)\n",
    "            \n",
    "            for e in pag_azienda_value:\n",
    "                azienda_value.append(e.text)\n",
    "            d_azienda = dict(zip(azienda_value, azienda_span))\n",
    "        \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            valutazione = general_button[button_mapping['Valutazione']] # Valutazione\n",
    "            #recensioni = general_button[2] # Recensioni\n",
    "            \n",
    "            ## Cambio foglio \n",
    "            valutazione.click()\n",
    "            pag_valutazione = driver.find_elements(By.CSS_SELECTOR, \".css-a7hxlj.e121l59f1\")\n",
    "            a = np.random.choice([x for x in range(7,15)])\n",
    "            time_sleep = time_sleep + a \n",
    "            time.sleep(a)\n",
    "            valutazione_1 = [pag_valutazione[0].text, pag_valutazione[2].text, pag_valutazione[4].text,pag_valutazione[6].text, pag_valutazione[8].text]\n",
    "            valutazione_2 = [pag_valutazione[1].text, pag_valutazione[3].text, pag_valutazione[5].text,pag_valutazione[7].text, pag_valutazione[9].text]\n",
    "            print('scraped evaluation page')\n",
    "\n",
    "            d_valutazione = dict(zip(valutazione_1, valutazione_2))\n",
    "        \n",
    "        except:\n",
    "            pass  \n",
    "        # to add benefit e stipendio\n",
    "\n",
    "            \n",
    "        \n",
    "    d = {**d_valutazione, **d_azienda}\n",
    "        \n",
    "    driver.quit()\n",
    "    \n",
    "    \n",
    "    df2 = pd.DataFrame.from_dict(d,  orient='index').T\n",
    "    df2['job_link']=base_url\n",
    "    \n",
    "    df_append_2 = df_append_2.append(df2).reset_index(drop=True)\n",
    "    \n",
    "\n",
    "end_time = time.time()\n",
    "print('Total pages scraped:', len(links), '\\n')\n",
    "print(\"Runtime:\", round(end_time - start_time), \"seconds\" + '\\nTime sleep: ', time_sleep, 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_append.merge(df_append_2, how='left', on='job_link')\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(path + '\\scraping_v1_040223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append_2.to_csv(path + r'\\anagrafica_aziende_v1_040223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.getcwd() + '\\data\\prova_050223.csv'\n",
    "# path\n",
    "#df_append.to_csv(path, index=False)\n",
    "# df = pd.read_csv(path)\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
