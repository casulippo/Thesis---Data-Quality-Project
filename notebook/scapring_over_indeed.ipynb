{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install getuseragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1f7a9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getuseragent import UserAgent\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5eab274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "useragent = UserAgent()\n",
    "\n",
    "theuseragent = useragent.Random()\n",
    "headers = {'User-Agent': theuseragent}\n",
    "header = {\n",
    "    \"user-agent\": theuseragent ,\n",
    "    'referer':'https://www.google.com/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd9920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "url = \"https://webcache.googleusercontent.com/search?q=cache:WQPzFq8hUh4J:https://it.indeed.com/Milano,-Lombardia-offerte-lavoro-Data-Scientist&cd=1&hl=it&ct=clnk&gl=it\"\n",
    "r = requests.get(url, headers=header)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b62ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response works\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52120c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards=[]\n",
    "\n",
    "company=[]\n",
    "\n",
    "job_title=[]\n",
    "\n",
    "location=[]\n",
    "\n",
    "rating=[]\n",
    "\n",
    "published_date=[]\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "job_list = soup.find('ul')\n",
    "\n",
    "for li in job_list.find_all(\"li\"):\n",
    "    cards.append(li.text)\n",
    "    company_name = li.find_all('span', 'companyName')\n",
    "    job = li.find_all('h2', 'jobTitle')\n",
    "    company_location = li.find_all('div', 'companyLocation')\n",
    "    rating_jobs = li.find_all('span', 'ratingNumber')\n",
    "    pulished = li.find_all('span', 'date')\n",
    "\n",
    "    if len(list(company_name))> 0:\n",
    "        for e in company_name:\n",
    "            company.append(e.text)\n",
    "    else:\n",
    "        company.append('')\n",
    "        \n",
    "    if len(list(company_location))> 0:\n",
    "        for e in job:\n",
    "            job_title.append(e.text)\n",
    "    else:\n",
    "        job_title.append('')\n",
    "    \n",
    "    if len(list(company_location))> 0:\n",
    "        for e in company_location:\n",
    "            location.append(e.text)\n",
    "    else:\n",
    "        location.append('')\n",
    "        \n",
    "    if len(list(rating_jobs))> 0:\n",
    "        for e in rating_jobs:\n",
    "            rating.append(e.text)\n",
    "    else:\n",
    "        rating.append('')\n",
    "\n",
    "    if len(list(pulished))> 0:\n",
    "        for e in pulished:\n",
    "            published_date.append(e.text)\n",
    "    else:\n",
    "        published_date.append('')\n",
    "        \n",
    "        \n",
    "\n",
    "dict_jobs = {'Company_Name': company, 'Job_Title': job_title,\\\n",
    "             'Location': location, 'rating':rating,\\\n",
    "             'Date':published_date}\n",
    "\n",
    "df = pd.DataFrame.from_dict(dict_jobs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc604d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ea11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cae42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3fd9e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getuseragent import UserAgent\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b7d11d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=data+scientist&sc.keyword=data+scientist&locT=C&locId=1147401&jobType=\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL2 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb96dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3ac8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(URL)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6d6352a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "location=[]\n",
    "\n",
    "\n",
    "job_search_div = soup.select('div#JobSearch')[0]\n",
    "\n",
    "div_inside_job_search = job_search_div.select('div')[0]\n",
    "\n",
    "ul_inside_div = div_inside_job_search.select('ul')[0]\n",
    "\n",
    "lis = ul_inside_div.find_all('li') # sono tutti i li, ogni li individua un'offerta di lavoro\n",
    "\n",
    "# HTML E' COSÃ¬ COMPOSTO\n",
    "# OGNI LAVORO CORRISPONDE AD UN LI\n",
    "# OGNI LI E' COMPOSTO DA 2 DIV\n",
    "# IL PRIMO DIV CONTIENE LA PARTE PIU' A SINISTRA, POSSO OTTENERE SOLO IL RATING, IL RESTO NON MI INTERESSA\n",
    "# IL SECONOD DIV CONTIENE LE INFO CHE MI INTERESSANTO DI PIU'\n",
    "# ENTRIAMO NEL SECONDO DIV CHE E' COMPOSTO DA:\n",
    "\n",
    "#### UN DIV CHE AL SUO INTERNO HA UNA A, DENTRO LA A DENTRO SPAN TROVI LA COMPAGNIA CHE STA OFFREND L'OFFERTA PUOI ESTRARLA\n",
    "#### un A da dove estrai il nome della compagnia\n",
    "#### UNA A DOVE PUOI ESTRARE LA JOB TITLE\n",
    "#### UN DIV DA DOVE PUOI ESTRARRE LA CITTA'\n",
    "#### UN DIV CHE AL SUO INTERNO HA UN ALTRO DIV DA DOVE PUOI ESTRARRE LA RAL\n",
    "#### UN DIV CHE AL SUO INTERNO HA UN ALTRO DIV DA DOVE PUOI ESTRARRE LA DAT DI PUBBLICAZIONE DELL'OFFERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c0861b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Herewith Inc.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis[0].find_all('div')[1].find_all('a')[0].select_one('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf961262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Junior Data Scientist'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis[0].find_all('div')[1].find_all('a')[1].select_one('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fea46850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'San Francisco, CA'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis[0].find_all('div')[1].find_all('div')[2].select_one('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d329857e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$87K - $132K (Glassdoor est.)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis[0].find_all('div')[1].find_all('div')[3].find_all('div')[0].select_one('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9839f1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2d'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis[0].find_all('div')[1].find_all('div')[3].find_all('div')[1].find_all('div')[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db054e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/partner/jobListing.htm?pos=101&ao=1136043&s=58&guid=00000185dfab1674b0b0116f7cad1f65&src=GD_JOB_AD&t=SR&vt=w&cs=1_1008434e&cb=1674494810174&jobListingId=1008419952413&jrtk=3-0-1gnfqm5objm5c801-1gnfqm5ouihl5801-fb443ab3ed21f89c-'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis[0].find_all('div')[1].find_all('a')[1][\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5296ee52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ef0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd2013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e0f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cdca2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.glassdoor.it/Lavoro/milano-data-scientist-lavori-SRCH_IL.0,6_IC2802090_KO7,21.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=Data%2520Scie&typedLocation=Milano&context=Jobs&dropdown=0\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e3377a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "location=[]\n",
    "\n",
    "\n",
    "job_search_div = soup.select('div#JobSearch')[0]\n",
    "\n",
    "div_inside_job_search = job_search_div.select('div')[0]\n",
    "\n",
    "ul_inside_div = div_inside_job_search.select('ul')[0]\n",
    "\n",
    "lis = ul_inside_div.find_all('li') # sono tutti i li, ogni li individua un'offerta di lavoro\n",
    "\n",
    "# HTML E' COSÃ¬ COMPOSTO\n",
    "# OGNI LAVORO CORRISPONDE AD UN LI\n",
    "# OGNI LI E' COMPOSTO DA 2 DIV\n",
    "# IL PRIMO DIV CONTIENE LA PARTE PIU' A SINISTRA, POSSO OTTENERE SOLO IL RATING, IL RESTO NON MI INTERESSA\n",
    "# IL SECONOD DIV CONTIENE LE INFO CHE MI INTERESSANTO DI PIU'\n",
    "# ENTRIAMO NEL SECONDO DIV CHE E' COMPOSTO DA:\n",
    "\n",
    "#### UN DIV CHE AL SUO INTERNO HA UNA A, DENTRO LA A DENTRO SPAN TROVI LA COMPAGNIA CHE STA OFFREND L'OFFERTA PUOI ESTRARLA\n",
    "#### un A da dove estrai il nome della compagnia\n",
    "#### UNA A DOVE PUOI ESTRARE LA JOB TITLE\n",
    "#### UN DIV DA DOVE PUOI ESTRARRE LA CITTA'\n",
    "#### UN DIV CHE AL SUO INTERNO HA UN ALTRO DIV DA DOVE PUOI ESTRARRE LA RAL\n",
    "#### UN DIV CHE AL SUO INTERNO HA UN ALTRO DIV DA DOVE PUOI ESTRARRE LA DAT DI PUBBLICAZIONE DELL'OFFERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e5b4df8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Engine srl'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis[0].find_all('div')[1].find_all('a')[0].select_one('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51c6be20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Scientist'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis[0].find_all('div')[1].find_all('a')[1].select_one('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "afe5d079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italia'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis[0].find_all('div')[1].find_all('div')[2].select_one('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1eecc73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20.000\\xa0â¬ - 30.000\\xa0â¬ (Stima azienda)'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis[0].find_all('div')[1].find_all('div')[3].find_all('div')[0].select_one('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7d615291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Candidatura rapida'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis[0].find_all('div')[1].find_all('div')[3].find_all('div')[1].find_all('div')[2].text ## candidatura rapida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "24792354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract maximum number of jobs stated, only applicable for the \"base\" url\n",
    "def extract_maximums(base_url):\n",
    "    page_soup,_ = requestAndParse(base_url)\n",
    "\n",
    "    tmp_match_1 = [item for item in page_soup.find_all(\"p\") if \"data-test\" in item.attrs][0]\n",
    "    # Fixed the issue of the change of offset of item.attrs from [-1] to [-2] for pages\n",
    "    tmp_match_2 = [item for item in page_soup.find_all(\"div\") if \"data-test\" in item.attrs][-2]\n",
    "    \n",
    "    maxJobs_raw = tmp_match_1.get_text()    # e.g. 7,764 Jobs\n",
    "    maxPages_raw = tmp_match_2.get_text()   # e.g. Page 1 of 30\n",
    "\n",
    "    try:\n",
    "        # fixied the issue of \"Assumptions invalid\" given \"Jobs\" was changed to \"jobs\"\n",
    "        assert \"jobs\" in maxJobs_raw\n",
    "        assert \"Page\" in maxPages_raw\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"[ERROR] Assumptions invalid\")\n",
    "\n",
    "    maxJobs = re.sub(r\"\\D\", \"\", maxJobs_raw)\n",
    "    maxPages = re.sub(r\"\\D\", \"\", maxPages_raw)[1:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return(int(maxJobs), int(maxPages))\n",
    "\n",
    "\n",
    "# extract listing urls\n",
    "def extract_listings(page_soup):\n",
    "    # this is slower but more robust:\n",
    "    # get all links regardless of type and extract those that match\n",
    "    listings_list = list()\n",
    "\n",
    "    for a in page_soup.find_all('a', href=True):\n",
    "        if \"/partner/jobListing.htm?\" in a['href']:\n",
    "            # print(\"Found the URL:\", a['href'])\n",
    "            listings_list.append(\"www.glassdoor.com\" + a['href'])\n",
    "\n",
    "    listings_set = set(listings_list)\n",
    "    jobCount = len(listings_set)\n",
    "\n",
    "    try:\n",
    "        assert jobCount != 0\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"[ERROR] Assumptions invalid\")\n",
    "\n",
    "    return listings_set, jobCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7cc47fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = extract_listings(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4b83d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "def get_page_urls(soup):\n",
    "    #soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "    urls = []\n",
    "    for link in links:\n",
    "        href = link.get('href', '')\n",
    "        if href.startswith('http'): \n",
    "            urls.append(href)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8c671e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://help.glassdoor.com/GlassDoorHome/en_US',\n",
       " 'https://www.glassdoor.com/about-us/',\n",
       " 'https://www.glassdoor.com/blog/',\n",
       " 'https://www.glassdoor.com/research/',\n",
       " 'https://www.glassdoor.com/blog/guides/',\n",
       " 'https://help.glassdoor.com',\n",
       " 'https://help.glassdoor.com/article/Community-Guidelines/en_US',\n",
       " 'https://hrtechprivacy.com/brands/glassdoor#privacypolicy',\n",
       " 'https://hrtechprivacy.com/',\n",
       " 'http://resources.glassdoor.com/advertising-on-glassdoor.html',\n",
       " 'https://play.google.com/store/apps/details?id=com.glassdoor.app&hl=en&referrer=utm_source%3Dglassdoor%26utm_medium%3Dcta%26utm_campaign%3Ddownloadappicon',\n",
       " 'https://itunes.apple.com/us/app/glassdoor-job-search-salaries/id589698942?mt=8&l=eng',\n",
       " 'https://www.facebook.com/Glassdoor/',\n",
       " 'https://twitter.com/Glassdoor',\n",
       " 'https://www.youtube.com/Glassdoor',\n",
       " 'https://www.instagram.com/glassdoor']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_page_urls(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad8573",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.glassdoor.com/Job/san-francisco-data-scientist-jobs-SRCH_IL.0,13_IC1147401_KO14,28_IP4.htm?includeNoSalaryJobs=true&pgc=AB4AAoEAPAAAAAAAAAAAAAAAAfbAZ3QATwECAQ8qBwD2%2Fd87IpWuODZT3EFV8ktP%2F1uP9lutIA7rB5jPVtoRRNQszLLvZfkJ3mYniqMmLL49UN6eLUwyytthr4EiXyK6pM%2FbflTEosgAAA%3D%3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.glassdoor.com/Job/san-francisco-data-scientist-jobs-SRCH_IL.0,13_IC1147401_KO14,28_IP5.htm?includeNoSalaryJobs=true&pgc=AB4ABIEAeAAAAAAAAAAAAAAAAfbAZ3QAZwEDAQ8gEiwLDBnxzsmuvygmh3%2FjUKXljGR6VXkkQF1n%2B3B2S3%2BZNMGw20shEiu%2BkCLTweG5%2FZxDzLAccr4X3Or%2BdwwzCs%2FSEWc6rFVNpJZTV8koadvwTi45lqX%2FSVBXj9PLwdi5i5wAAA%3D%3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "34884047",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'data-scientist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "00d4c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=\"+keyword+\"&sc.keyword=\"+keyword+\"&locT=&locId=&jobType=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "faeb5185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=data-scientist&sc.keyword=data-scientist&locT=&locId=&jobType=\n"
     ]
    }
   ],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c8fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
